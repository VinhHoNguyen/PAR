# -*- coding: utf-8 -*-
"""Prompt_Market1501

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mqZGPc3pjXM-NsJD8m6Wnr7I0ipEj3fi
"""

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  CELL 1: MOUNT GOOGLE DRIVE                                  â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from google.colab import drive
drive.mount('/content/drive')

import os
CHECKPOINT_DIR = '/content/drive/MyDrive/PromptPAR_checkpoints/Vit_Market1501'
os.makedirs(CHECKPOINT_DIR, exist_ok=True)
os.makedirs('/data/jinjiandong', exist_ok=True)

print(f"âœ… Checkpoint dir: {CHECKPOINT_DIR}")

# Commented out IPython magic to ensure Python compatibility.
# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  CELL 3: CLONE REPOSITORIES                                  â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import os
import shutil

# %cd /content

# Clone OpenPAR
if os.path.exists('/content/OpenPAR'):
    shutil.rmtree('/content/OpenPAR')
! git clone https://github.com/Event-AHU/OpenPAR.git
print("âœ… Cloned OpenPAR")

# Clone Market-1501 Attributes
if os.path.exists('/content/Market-1501_Attribute'):
    shutil.rmtree('/content/Market-1501_Attribute')
!git clone https://github.com/vana77/Market-1501_Attribute.git
print("âœ… Cloned Market-1501_Attribute")

# Verify
!ls -la /content/

# Commented out IPython magic to ensure Python compatibility.
# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  CELL 4: CÃ€I Äáº¶T DEPENDENCIES                                â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# %cd /content/OpenPAR/PromptPAR

! pip install -q ftfy regex tqdm easydict scipy
!pip install -q git+https://github.com/openai/CLIP.git

print("\nâœ… Dependencies installed")

# Commented out IPython magic to ensure Python compatibility.
# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  CELL 5: Táº¢I MARKET-1501 DATASET                             â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import os

os.makedirs('/content/data', exist_ok=True)
# %cd /content/data

# Táº£i Market-1501
if not os.path. exists('/content/data/Market-1501-v15.09.15'):
    print("ğŸ”„ Äang táº£i Market-1501...")
    !pip install -q gdown
    !gdown "https://drive.google.com/uc?id=0B8-rUzbwVRk0c054eEozWG9COHM" -O Market-1501-v15.09.15.zip --fuzzy
    !unzip -q Market-1501-v15.09.15.zip
    !rm Market-1501-v15.09.15. zip
    print("âœ… ÄÃ£ táº£i vÃ  giáº£i nÃ©n Market-1501")
else:
    print("âœ… Market-1501 Ä‘Ã£ tá»“n táº¡i")

! ls -la /content/data/Market-1501-v15.09.15/

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  CELL 6: Táº¢I VIT PRETRAINED MODEL                            â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import os

os.makedirs('/data/jinjiandong', exist_ok=True)

vit_path = '/data/jinjiandong/jx_vit_base_p16_224-80ecf9dd.pth'

if not os.path.exists(vit_path):
    print("ğŸ”„ Äang táº£i ViT pretrained...")
    !wget -q https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_224-80ecf9dd.pth -O {vit_path}

if os.path.exists(vit_path):
    size = os.path.getsize(vit_path) / 1024 / 1024
    print(f"âœ… ViT pretrained: {size:.1f} MB")
else:
    print("âŒ Táº£i ViT tháº¥t báº¡i!")

# Commented out IPython magic to ensure Python compatibility.
# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  CELL 7: Sá»¬A CODE PROMPTPAR Äá»‚ Há»– TRá»¢ MARKET1501             â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import os
import shutil

# Clone láº¡i Ä‘á»ƒ Ä‘áº£m báº£o code sáº¡ch
# %cd /content
if os.path.exists('/content/OpenPAR'):
    shutil.rmtree('/content/OpenPAR')
! git clone -q https://github.com/Event-AHU/OpenPAR.git
print("âœ… Cloned fresh OpenPAR")

# ========== 1. Sá»¬A clip/model.py ==========
model_py = '/content/OpenPAR/PromptPAR/clip/model.py'

with open(model_py, 'r') as f:
    content = f.read()

# Hiá»ƒn thá»‹ trÆ°á»›c khi sá»­a
print("ğŸ” TRÆ¯á»šC KHI Sá»¬A:")
for line in content.split('\n')[13:19]:
    print(f"   {line[:80]}")

# Sá»­a táº¥t cáº£ cÃ¡c pattern cÃ³ thá»ƒ cho model.py
replacements = [
    # Pattern 1: datasets_attrnum gá»‘c
    ("datasets_attrnum={'PA100k':26,'RAPV1':51,'PETA':35,'PETAzs':35,'UPAR':40,'RAPzs':53,'RAPV2':54,'WIDER':14,\"RAPV1Expand\":51}",
     "datasets_attrnum={'PA100k':26,'RAPV1':51,'PETA':35,'PETAzs':35,'UPAR':40,'RAPzs':53,'RAPV2':54,'WIDER':14,'RAPV1Expand':51,'Market1501':27}"),
    # Pattern 2 (náº¿u Ä‘Ã£ cÃ³ Market1501 nhÆ°ng sai sá»‘)
    ("'Market1501':39", "'Market1501':27"),
    # Assert pattern
    ("['PA100k', 'RAPV1','RAPV2','PETA','WIDER','PETAzs','RAPzs','UPAR','YCJC',\"RAPV1Expand\"]",
     "['PA100k', 'RAPV1','RAPV2','PETA','WIDER','PETAzs','RAPzs','UPAR','YCJC','RAPV1Expand','Market1501']"),
]

for old, new in replacements:
    if old in content:
        content = content.replace(old, new)
        print(f"\nâœ… ÄÃ£ thay tháº¿ pattern trong model.py")

# Fallback: Sá»­a tá»«ng dÃ²ng náº¿u pattern khÃ´ng khá»›p
lines = content.split('\n')
new_lines = []
for line in lines:
    # Sá»­a dÃ²ng assert
    if "assert args.dataset in [" in line and "Market1501" not in line:
        new_lines.append("assert args.dataset in ['PA100k', 'RAPV1','RAPV2','PETA','WIDER','PETAzs','RAPzs','UPAR','YCJC','RAPV1Expand','Market1501'], \\")
    # Sá»­a dÃ²ng datasets_attrnum
    elif "datasets_attrnum=" in line and "Market1501" not in line:
        new_lines.append("datasets_attrnum={'PA100k':26,'RAPV1':51,'PETA':35,'PETAzs':35,'UPAR':40,'RAPzs':53,'RAPV2':54,'WIDER':14,'RAPV1Expand':51,'Market1501':27}")
    else:
        new_lines.append(line)
content = '\n'.join(new_lines)

with open(model_py, 'w') as f:
    f.write(content)

# Hiá»ƒn thá»‹ sau khi sá»­a
print("\nğŸ” SAU KHI Sá»¬A:")
with open(model_py, 'r') as f:
    content = f.read()
for line in content.split('\n')[13:19]:
    print(f"   {line[:80]}")

# Verify model.py
if "'Market1501':27" in content:
    print("\nâœ… OK! Market1501 = 27 attributes trong model.py")
else:
    print("\nâŒ ChÆ°a sá»­a Ä‘Æ°á»£c model.py! Cáº§n sá»­a thá»§ cÃ´ng")

print("âœ… ÄÃ£ sá»­a clip/model.py")

# ========== 2. Sá»¬A dataset/AttrDataset.py ==========
attr_py = '/content/OpenPAR/PromptPAR/dataset/AttrDataset.py'

with open(attr_py, 'r') as f:
    content = f.read()

# ThÃªm Market1501
content = content.replace(
    "['PA100k', 'RAPV1','RAPV2','PETA','WIDER','RAPzs','PETAzs','UPAR','YCJC',]",
    "['PA100k', 'RAPV1','RAPV2','PETA','WIDER','RAPzs','PETAzs','UPAR','YCJC','Market1501']"
)

# Sá»­a Ä‘Æ°á»ng dáº«n dataset
content = content.replace(
    "dataset_dir='/data/jinjiandong/datasets/'",
    "dataset_dir='/content/data/'"
)

with open(attr_py, 'w') as f:
    f.write(content)

print("âœ… ÄÃ£ sá»­a dataset/AttrDataset.py")

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  CELL 8: Táº O DATASET PICKLE CHO MARKET1501                   â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import scipy.io
import numpy as np
import os
import pickle
import shutil
from easydict import EasyDict

# ========== PATHS ==========
MARKET_DIR = '/content/data/Market-1501-v15.09.15'
ATTR_FILE = '/content/Market-1501_Attribute/market_attribute.mat'
SAVE_DIR = '/content/data/Market1501'

# ========== CHECK FILES ==========
print("ğŸ” Kiá»ƒm tra files...")
if not os.path.exists(MARKET_DIR):
    raise Exception("âŒ ChÆ°a cÃ³ Market-1501! Cháº¡y Cell 5 trÆ°á»›c.")
if not os.path.exists(ATTR_FILE):
    raise Exception("âŒ ChÆ°a cÃ³ market_attribute.mat! Cháº¡y Cell 3 trÆ°á»›c.")
print("âœ… Files OK")

# XÃ³a vÃ  táº¡o láº¡i thÆ° má»¥c
if os.path.exists(SAVE_DIR):
    shutil.rmtree(SAVE_DIR)
os.makedirs(SAVE_DIR)

# ========== LOAD .MAT FILE ==========
mat_data = scipy.io.loadmat(ATTR_FILE)
market_attr = mat_data['market_attribute'][0][0]
train_attr_mat = market_attr['train'][0][0]
test_attr_mat = market_attr['test'][0][0]

# Láº¥y 27 attributes tá»« .mat
attr_names = [name for name in train_attr_mat.dtype.names if name != 'image_index']
print(f"ğŸ“Š Attributes tá»« .mat: {len(attr_names)}")

# ========== GET IMAGE LISTS ==========
train_dir = os.path.join(MARKET_DIR, 'bounding_box_train')
test_dir = os.path.join(MARKET_DIR, 'bounding_box_test')

train_images = sorted([f for f in os.listdir(train_dir)
                      if f.endswith('.jpg') and not f.startswith('-1')])
test_images = sorted([f for f in os.listdir(test_dir)
                     if f.endswith('.jpg') and not f.startswith('-1') and not f.startswith('0000')])

print(f"ğŸ–¼ï¸ Train images: {len(train_images)}")
print(f"ğŸ–¼ï¸ Test images: {len(test_images)}")

# ========== CREATE DATASET ==========
image_name_list = []
label_list = []
train_idx = []
test_idx = []
idx = 0

# Process TRAINING images
print("\nğŸ”„ Processing training images...")
for img_name in train_images:
    try:
        identity_id = int(img_name.split('_')[0])
        if 1 <= identity_id <= 751:
            image_name_list.append(os.path.join('bounding_box_train', img_name))
            attr_idx = identity_id - 1
            label = [max(0, int(train_attr_mat[attr_name][0][attr_idx]) - 1) for attr_name in attr_names]
            label_list.append(label)
            train_idx.append(idx)
            idx += 1
    except:
        continue
print(f"   âœ… Train samples: {len(train_idx)}")

# Process TEST images
print("ğŸ”„ Processing test images...")
for img_name in test_images:
    try:
        identity_id = int(img_name.split('_')[0])
        if 1 <= identity_id <= 750:
            image_name_list.append(os.path.join('bounding_box_test', img_name))
            attr_idx = identity_id - 1
            label = [max(0, int(test_attr_mat[attr_name][0][attr_idx]) - 1) for attr_name in attr_names]
            label_list.append(label)
            test_idx.append(idx)
            idx += 1
    except:
        continue
print(f"   âœ… Test samples: {len(test_idx)}")

# ========== CREATE EASYDICT ==========
dataset = EasyDict()
dataset.description = 'market1501'
dataset.root = SAVE_DIR
dataset.image_name = image_name_list
dataset.label = np.array(label_list, dtype=np.float32)
dataset.attributes = attr_names

dataset.partition = EasyDict()
dataset.partition.train = np.array(train_idx, dtype=np.int64)
dataset.partition.val = np.array([], dtype=np.int64)
dataset.partition.test = np.array(test_idx, dtype=np.int64)
dataset.partition.trainval = np.array(train_idx, dtype=np.int64)

# Weights
train_labels = dataset.label[dataset.partition.train]
label_ratio = np.clip(np.mean(train_labels, axis=0), 0.01, 0.99)
dataset.weight_train = np.exp(-label_ratio).astype(np.float32)
dataset.weight_trainval = dataset.weight_train.copy()

# ========== SAVE PICKLE ==========
pkl_path = os.path.join(SAVE_DIR, 'pad.pkl')
with open(pkl_path, 'wb') as f:
    pickle.dump(dataset, f)
print(f"\nâœ… Saved: {pkl_path}")

# ========== CREATE SYMLINKS ==========
os.symlink(train_dir, os.path.join(SAVE_DIR, 'bounding_box_train'))
os.symlink(test_dir, os.path.join(SAVE_DIR, 'bounding_box_test'))
print("âœ… Created symlinks")

# ========== VERIFY ==========
print("\n" + "=" * 60)
print("ğŸ“‹ DATASET SUMMARY")
print("=" * 60)
if os.path.exists(pkl_path):
    size = os.path.getsize(pkl_path) / 1024 / 1024
    print(f"âœ… pad.pkl: {size:.2f} MB")
print(f"âœ… Labels shape: {dataset.label.shape}")
print(f"âœ… Attributes: {len(dataset.attributes)}")
print(f"âœ… Train: {len(dataset.partition.train)}")
print(f"âœ… Test: {len(dataset.partition.test)}")

if len(dataset.attributes) == dataset.label.shape[1]:
    print(f"\nğŸ‰ THÃ€NH CÃ”NG! attributes = labels = {len(dataset.attributes)}")
    print("Cháº¡y Cell 10 Ä‘á»ƒ training")
else:
    print(f"\nâŒ MISMATCH!")

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  CELL 9: TRAINING CONFIGURATION                              â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ==================== THAY Äá»”I á» ÄÃ‚Y ====================
EPOCHS = 30              # Test: 3 | Cháº¡y tháº­t: 30
BATCH_SIZE = 16
SAVE_FREQ = 5           # LÆ°u checkpoint má»—i N epoch
# ========================================================

print("=" * 60)
print("ğŸ“‹ TRAINING CONFIGURATION")
print("=" * 60)
print(f"  Epochs:         {EPOCHS}")
print(f"  Batch size:     {BATCH_SIZE}")
print(f"  Save frequency: Every {SAVE_FREQ} epoch(s)")
print(f"  Checkpoint:     /content/drive/MyDrive/PromptPAR_checkpoints/Vit_Market1501")
print("=" * 60)

# Commented out IPython magic to ensure Python compatibility.
# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  CELL 10: TRAINING (LÆ¯U THáº²NG VÃ€O DRIVE)                     â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# %cd /content/OpenPAR/PromptPAR

import os
import shutil

# Sá»­ dá»¥ng biáº¿n config tá»« Cell 9
# (Äáº£m báº£o Ä‘Ã£ cháº¡y Cell 9 trÆ°á»›c)
try:
    _epochs = int(EPOCHS)
    _batch_size = int(BATCH_SIZE)
    _save_freq = int(SAVE_FREQ)
except NameError:
    print("âš ï¸ ChÆ°a cháº¡y Cell 9! Sá»­ dá»¥ng giÃ¡ trá»‹ máº·c Ä‘á»‹nh")
    _epochs = 30
    _batch_size = 16
    _save_freq = 5
except (TypeError, ValueError) as e:
    print(f"âš ï¸ GiÃ¡ trá»‹ config khÃ´ng há»£p lá»‡: {e}. Sá»­ dá»¥ng giÃ¡ trá»‹ máº·c Ä‘á»‹nh")
    _epochs = 30
    _batch_size = 16
    _save_freq = 5

# Táº¡o thÆ° má»¥c trong Drive
CHECKPOINT_DIR = "/content/drive/MyDrive/PromptPAR_checkpoints/Vit_Market1501"
os.makedirs(CHECKPOINT_DIR, exist_ok=True)

# Táº¡o symlink tá»« local output sang Drive
LOCAL_OUTPUT = "/content/OpenPAR/PromptPAR/exp_result"

# Xá»­ lÃ½ symlink Ä‘Ãºng cÃ¡ch
if os.path.islink(LOCAL_OUTPUT):
    os.unlink(LOCAL_OUTPUT)
    print(f"ğŸ”— ÄÃ£ xÃ³a symlink cÅ©")
elif os.path.isdir(LOCAL_OUTPUT):
    # Di chuyá»ƒn ná»™i dung hiá»‡n cÃ³ vÃ o Drive trÆ°á»›c khi xÃ³a
    print(f"ğŸ“ ThÆ° má»¥c exp_result Ä‘Ã£ tá»“n táº¡i, di chuyá»ƒn ná»™i dung vÃ o Drive...")
    for item in os.listdir(LOCAL_OUTPUT):
        src = os.path.join(LOCAL_OUTPUT, item)
        dst = os.path.join(CHECKPOINT_DIR, item)
        if os.path.isfile(src):
            shutil.copy2(src, dst)
            print(f"   âœ… Copied: {item}")
    shutil.rmtree(LOCAL_OUTPUT)

# Táº¡o symlink má»›i
os.symlink(CHECKPOINT_DIR, LOCAL_OUTPUT)
print(f"ğŸ”— Symlink: {LOCAL_OUTPUT} â†’ {CHECKPOINT_DIR}")

# Verify symlink hoáº¡t Ä‘á»™ng
if os.path.islink(LOCAL_OUTPUT) and os.path.exists(LOCAL_OUTPUT):
    print("âœ… Symlink hoáº¡t Ä‘á»™ng tá»‘t!")
else:
    print("âŒ Symlink cÃ³ váº¥n Ä‘á»!")
    raise Exception("Symlink khÃ´ng hoáº¡t Ä‘á»™ng!")

print(f"\nğŸ“‹ TRAINING CONFIG:")
print(f"   Epochs:     {_epochs}")
print(f"   Batch size: {_batch_size}")
print(f"   Save freq:  {_save_freq}")
print("\nğŸš€ Báº¯t Ä‘áº§u training...\n")

!python train.py Market1501 \
    --batchsize {_batch_size} \
    --epoch {_epochs} \
    --height 224 \
    --width 224 \
    --lr 8e-3 \
    --weight_decay 1e-4 \
    --clip_lr 4e-3 \
    --clip_weight_decay 1e-4 \
    --text_prompt 3 \
    --vis_prompt 50 \
    --vis_depth 24 \
    --div_num 4 \
    --overlap_row 2 \
    --mm_layers 1 \
    --smooth_param 0.1 \
    --ag_threshold 0.5 \
    --train_split trainval \
    --valid_split test \
    --save_freq {_save_freq} \
    --use_div \
    --use_textprompt \
    --use_mm_former \
    --use_GL \
    --dir $CHECKPOINT_DIR

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  CELL 10.1: VERIFY TRAINING OUTPUT                           â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import os
import glob
from datetime import datetime

print("\n" + "=" * 60)
print("ğŸ“‹ VERIFY TRAINING OUTPUT")
print("=" * 60)

CHECKPOINT_DIR = "/content/drive/MyDrive/PromptPAR_checkpoints/Vit_Market1501"
LOCAL_OUTPUT = "/content/OpenPAR/PromptPAR/exp_result"

# Kiá»ƒm tra symlink
print("\nğŸ”— SYMLINK STATUS:")
if os.path.islink(LOCAL_OUTPUT):
    target = os.readlink(LOCAL_OUTPUT)
    print(f"   âœ… Symlink active: {LOCAL_OUTPUT} â†’ {target}")
    if os.path.exists(LOCAL_OUTPUT):
        print(f"   âœ… Target accessible")
    else:
        print(f"   âŒ Target NOT accessible!")
else:
    print(f"   âŒ KhÃ´ng pháº£i symlink!")

# Liá»‡t kÃª checkpoints trong Drive
print("\nğŸ“¦ CHECKPOINTS TRONG DRIVE:")
checkpoints = glob.glob(f'{CHECKPOINT_DIR}/**/*.pth', recursive=True)
checkpoints += glob.glob(f'{CHECKPOINT_DIR}/*.pth')
checkpoints = list(set(checkpoints))  # Remove duplicates

if checkpoints:
    checkpoints.sort(key=os.path.getmtime, reverse=True)
    for ckpt in checkpoints[:10]:  # Show max 10
        size = os.path.getsize(ckpt) / 1024 / 1024
        mtime = datetime.fromtimestamp(os.path.getmtime(ckpt))
        print(f"   ğŸ“¦ {os.path.basename(ckpt)}")
        print(f"      Size: {size:.1f} MB | Created: {mtime.strftime('%Y-%m-%d %H:%M:%S')}")
    if len(checkpoints) > 10:
        print(f"   ... vÃ  {len(checkpoints) - 10} files khÃ¡c")
else:
    print("   âš ï¸ ChÆ°a cÃ³ checkpoint nÃ o!")

# Tá»•ng káº¿t
print("\n" + "=" * 60)
if checkpoints:
    print(f"ğŸ‰ ÄÃƒ LÆ¯U {len(checkpoints)} CHECKPOINT(S) VÃ€O DRIVE!")
else:
    print("âš ï¸ ChÆ°a cÃ³ checkpoint - kiá»ƒm tra láº¡i training")

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  CELL 11: KIá»‚M TRA CHECKPOINT                                â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import os
import glob
from datetime import datetime

CHECKPOINT_DIR = "/content/drive/MyDrive/PromptPAR_checkpoints/Vit_Market1501"

print("ğŸ“ Checkpoints Ä‘Ã£ lÆ°u:")
print("=" * 60)

# TÃ¬m trong Drive
checkpoints = glob.glob(f'{CHECKPOINT_DIR}/**/*.pth', recursive=True)
checkpoints += glob.glob(f'{CHECKPOINT_DIR}/*.pth')
checkpoints = list(set(checkpoints))  # Remove duplicates

# TÃ¬m trong local
local_ckpts = glob.glob('/content/OpenPAR/PromptPAR/**/*.pth', recursive=True)

if checkpoints:
    checkpoints.sort(key=os.path.getmtime, reverse=True)
    print(f"âœ… Google Drive ({len(checkpoints)} files):")
    for ckpt in checkpoints:
        size = os.path.getsize(ckpt) / 1024 / 1024
        mtime = datetime.fromtimestamp(os.path.getmtime(ckpt))
        print(f"   ğŸ“¦ {os.path.basename(ckpt)} ({size:.1f} MB) - {mtime.strftime('%Y-%m-%d %H:%M:%S')}")

if local_ckpts:
    print(f"\nğŸ“ Local ({len(local_ckpts)} files):")
    for ckpt in local_ckpts:
        size = os.path.getsize(ckpt) / 1024 / 1024
        print(f"   ğŸ“¦ {os.path.basename(ckpt)} ({size:.1f} MB)")

    # Copy to Drive náº¿u chÆ°a cÃ³
    import shutil
    print("\nğŸ”„ Copying to Drive...")
    for ckpt in local_ckpts:
        dest = os.path.join(CHECKPOINT_DIR, os.path.basename(ckpt))
        if not os.path.exists(dest):
            shutil.copy(ckpt, dest)
            print(f"   âœ… {os.path.basename(ckpt)}")
        else:
            print(f"   â­ï¸ {os.path.basename(ckpt)} (Ä‘Ã£ cÃ³)")

if not checkpoints and not local_ckpts:
    print("âŒ ChÆ°a cÃ³ checkpoint nÃ o!")

# Commented out IPython magic to ensure Python compatibility.
# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  CELL 12: RESUME TRAINING (Náº¾U Bá»Š NGáº®T)                      â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# âš ï¸ UNCOMMENT VÃ€ CHáº Y Náº¾U COLAB Bá»Š NGáº®T
# TrÆ°á»›c tiÃªn cháº¡y Cell 1, 7, rá»“i cháº¡y cell nÃ y

# %cd /content/OpenPAR/PromptPAR

import os
import glob

CHECKPOINT_DIR = "/content/drive/MyDrive/PromptPAR_checkpoints/Vit_Market1501"

# Sá»­ dá»¥ng biáº¿n config tá»« Cell 9
try:
    _epochs = int(EPOCHS)
    _batch_size = int(BATCH_SIZE)
    _save_freq = int(SAVE_FREQ)
except NameError:
    print("âš ï¸ ChÆ°a cháº¡y Cell 9! Sá»­ dá»¥ng giÃ¡ trá»‹ máº·c Ä‘á»‹nh")
    _epochs = 30
    _batch_size = 16
    _save_freq = 5
except (TypeError, ValueError) as e:
    print(f"âš ï¸ GiÃ¡ trá»‹ config khÃ´ng há»£p lá»‡: {e}. Sá»­ dá»¥ng giÃ¡ trá»‹ máº·c Ä‘á»‹nh")
    _epochs = 30
    _batch_size = 16
    _save_freq = 5

# ========== TÃŒM CHECKPOINT Má»šI NHáº¤T ==========
def find_latest_checkpoint(checkpoint_dir):
    """TÃ¬m checkpoint má»›i nháº¥t trong thÆ° má»¥c"""
    # TÃ¬m táº¥t cáº£ file .pth
    patterns = [
        f'{checkpoint_dir}/**/*.pth',
        f'{checkpoint_dir}/*.pth',
    ]
    checkpoints = []
    for pattern in patterns:
        checkpoints.extend(glob.glob(pattern, recursive=True))
    checkpoints = list(set(checkpoints))  # Remove duplicates
    
    if not checkpoints:
        return None
    
    # Sáº¯p xáº¿p theo thá»i gian sá»­a Ä‘á»•i, má»›i nháº¥t trÆ°á»›c
    checkpoints.sort(key=os.path.getmtime, reverse=True)
    return checkpoints[0]

latest_ckpt = find_latest_checkpoint(CHECKPOINT_DIR)

print("=" * 60)
print("ğŸ“‹ RESUME TRAINING")
print("=" * 60)

if latest_ckpt:
    size = os.path.getsize(latest_ckpt) / 1024 / 1024
    from datetime import datetime
    mtime = datetime.fromtimestamp(os.path.getmtime(latest_ckpt))
    
    print(f"âœ… Checkpoint má»›i nháº¥t:")
    print(f"   ğŸ“¦ {latest_ckpt}")
    print(f"   Size: {size:.1f} MB")
    print(f"   Modified: {mtime.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"\nğŸ“‹ CONFIG:")
    print(f"   Epochs:     {_epochs}")
    print(f"   Batch size: {_batch_size}")
    print(f"   Save freq:  {_save_freq}")
    print("\nğŸš€ Resume training...\n")
    
    !python train.py Market1501 \
        --batchsize {_batch_size} \
        --epoch {_epochs} \
        --height 224 \
        --width 224 \
        --lr 8e-3 \
        --weight_decay 1e-4 \
        --clip_lr 4e-3 \
        --text_prompt 3 \
        --vis_prompt 50 \
        --vis_depth 24 \
        --div_num 4 \
        --save_freq {_save_freq} \
        --use_div \
        --use_textprompt \
        --use_mm_former \
        --checkpoint {latest_ckpt} \
        --dir $CHECKPOINT_DIR
else:
    print("âŒ KhÃ´ng tÃ¬m tháº¥y checkpoint nÃ o!")
    print(f"   ThÆ° má»¥c: {CHECKPOINT_DIR}")
    print("\nğŸ’¡ Cháº¡y Cell 10 Ä‘á»ƒ training tá»« Ä‘áº§u")